{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import chardet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In the datasets we are using, each country is associated with a country code.\n",
    "# Here, we are reading in the csv that contains these codes and creating\n",
    "# a dictionary so that we can access countries by their code rather than their name.\n",
    "# This is important because the names of countries have changed over the time period\n",
    "# we are looking at (e.g. USSR -> Russia, Ottoman Empire -> Turkey).\n",
    "# It is important to keep this in mind during our analysis as this will show up as\n",
    "# \"Russia\" having fought in WW2, for example, when really \"USSR\" fought in WW2.\n",
    "# This is okay for our purposes because we are not primarily concerned about\n",
    "# individual states but rather the quantitative things about states that are correlated with war.\n",
    "\n",
    "country_codes = pd.read_csv(\"correlates_of_war/COW-country-codes.csv\")\n",
    "country_codes.drop_duplicates(inplace=True)\n",
    "country_codes.set_index(\"CCode\", inplace=True)\n",
    "country_dict = country_codes.to_dict(\"index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'StateAbb': 'USA', 'StateNme': 'United States of America'}\n",
      "{'StateAbb': 'CAN', 'StateNme': 'Canada'}\n",
      "{'StateAbb': 'RUS', 'StateNme': 'Russia'}\n",
      "Not a valid country code\n"
     ]
    }
   ],
   "source": [
    "# Here we are checking that this worked correctly by plugging in some of\n",
    "# the country codes and making sure they are associated with the right country.\n",
    "\n",
    "print(country_dict[2]) # should be USA\n",
    "print(country_dict[20]) # should be Canada\n",
    "print(country_dict[365]) # should be Russia\n",
    "try:\n",
    "    print(country_dict[3]) # no country associated with this code, should throw a KeyError\n",
    "except KeyError:\n",
    "    print(\"Not a valid country code\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we are going to read in the rest of our csv files. Some of the files use Latin-1 encoding which\n",
    "# causes problems when we try read it in with pandas as pandas assumes UTF-8 by default. To make this simpler\n",
    "# I wrote a short function that will figure out the encoding. This isn't the most efficient, but it's\n",
    "# not too slow and it works.\n",
    "def get_encoding(filename):\n",
    "    with open(filename, \"rb\") as f:\n",
    "        return chardet.detect(f.read())[\"encoding\"]\n",
    "\n",
    "filename = \"correlates_of_war/COW War Data/Inter-StateWarData_v4.0.csv\"\n",
    "interstate_war = pd.read_csv(filename, encoding=get_encoding(filename))\n",
    "\n",
    "filename = \"correlates_of_war/COW War Data/Intra-State-Wars-v5.1/INTRA-STATE_State_participants v5.1 CSV.csv\"\n",
    "intrastate_war = pd.read_csv(filename, encoding=get_encoding(filename))\n",
    "\n",
    "filename = \"correlates_of_war/COW War Data/Extra-StateWarData_v4.0.csv\"\n",
    "extrastate_war = pd.read_csv(filename, encoding=get_encoding(filename))\n",
    "\n",
    "filename = \"correlates_of_war/Diplomatic Exchange/Diplomatic_Exchange_2006v1.csv\"\n",
    "diplomatic_exchanges = pd.read_csv(filename, encoding=get_encoding(filename))\n",
    "\n",
    "filename = \"correlates_of_war/Colonial Contiguity/contcol.csv\"\n",
    "colonial_contiguity = pd.read_csv(filename, encoding=get_encoding(filename))\n",
    "\n",
    "filename = \"correlates_of_war/Direct Contiguity/contdir.csv\"\n",
    "direct_contiguity = pd.read_csv(filename, encoding=get_encoding(filename))\n",
    "\n",
    "filename = \"correlates_of_war/Formal Alliances/alliance_v4.1_by_member_yearly.csv\"\n",
    "formal_alliances = pd.read_csv(filename, encoding=get_encoding(filename))\n",
    "\n",
    "filename = \"correlates_of_war/Militarized Interstate Disputes/MIDIP 5.0.csv\"\n",
    "mid = pd.read_csv(filename, encoding=get_encoding(filename))\n",
    "\n",
    "filename = \"correlates_of_war/Militarized Interstate Dispute Locations/MIDLOCI_2.1.csv\"\n",
    "midl = pd.read_csv(filename, encoding=get_encoding(filename))\n",
    "\n",
    "filename = \"correlates_of_war/National Material Capabilities/NMC-60-abridged/NMC-60-abridged.csv\"\n",
    "nmc = pd.read_csv(filename, encoding=get_encoding(filename))\n",
    "\n",
    "filename = \"correlates_of_war/State System Membership/majors2016.csv\"\n",
    "major_powers = pd.read_csv(filename, encoding=get_encoding(filename))\n",
    "\n",
    "filename = \"correlates_of_war/Territorial Change/tc2018.csv\"\n",
    "territorial_change = pd.read_csv(filename, encoding=get_encoding(filename))\n",
    "\n",
    "filename = \"correlates_of_war/Trade/National_COW_4.0.csv\"\n",
    "national_trade = pd.read_csv(filename, encoding=get_encoding(filename))\n",
    "\n",
    "filename = \"correlates_of_war/Trade/Dyadic_COW_4.0.csv\"\n",
    "dyadic_trade = pd.read_csv(filename, encoding=get_encoding(filename))\n",
    "\n",
    "filename = \"correlates_of_war/World Religion/WRP_national.csv\"\n",
    "national_religion = pd.read_csv(filename, encoding=get_encoding(filename))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Data Cleaning**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Luckily for us, the Correlates of War Project has spent a lot of time making their data as easy to use as possible, which includes interpolating missing data sometimes or indicating that the data is missing otherwise. For example, -9 typically means missing data. I've looked through the codebooks that are provided with each dataset and can say that everywhere negative integers occur, it is meant to signify data is missing or not applicable, and so we can safely replace all instances of negative integers with NaN. We do this so that these negative numbers don't affect our analysis later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It's important that we check that it is an int, as negative floats have meaning \n",
    "# (e.g. in location coordinates) and if we try to compare a string to 0 we get an error.\n",
    "def replace_missing(df):\n",
    "    return df.applymap((lambda x: np.nan if isinstance(x, int) and x < 0 else x))\n",
    "\n",
    "interstate_war = replace_missing(interstate_war)\n",
    "intrastate_war = replace_missing(intrastate_war)\n",
    "extrastate_war = replace_missing(extrastate_war)\n",
    "diplomatic_exchanges = replace_missing(diplomatic_exchanges)\n",
    "colonial_contiguity = replace_missing(colonial_contiguity)\n",
    "direct_contiguity = replace_missing(direct_contiguity)\n",
    "formal_alliances = replace_missing(formal_alliances)\n",
    "mid = replace_missing(mid)\n",
    "midl = replace_missing(midl)\n",
    "nmc = replace_missing(nmc)\n",
    "national_trade = replace_missing(national_trade)\n",
    "dyadic_trade = replace_missing(dyadic_trade)\n",
    "national_religion = replace_missing(national_religion)\n",
    "# territorial_change also uses '.' to indicate missing values\n",
    "territorial_change = replace_missing(territorial_change)\n",
    "territorial_change = territorial_change.applymap((lambda x: np.nan if x == '.' else x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# have to do something about missing data, if I want to just leave it, \n",
    "# need to explain why, could maybe do interpolation here"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Exploratory Data Analysis**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "what do we want to do"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_interwars = interstate_war.groupby(\"ccode\").size()\n",
    "num_intrawarsA = intrastate_war.groupby(\"CcodeA\").size()\n",
    "num_intrawarsB = intrastate_war.groupby(\"CcodeB\").size()\n",
    "num_extrawarsA = extrastate_war.groupby(\"CcodeA\").size()\n",
    "num_extrawarsB = extrastate_war.groupby(\"CcodeB\").size()\n",
    "# want to combine these into one"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
