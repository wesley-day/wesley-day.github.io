{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import chardet\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In the datasets we are using, each country is associated with a country code.\n",
    "# Here, we are reading in the csv that contains these codes and creating\n",
    "# a dictionary so that we can access countries by their code rather than their name.\n",
    "# This is important because the names of countries have changed over the time period\n",
    "# we are looking at (e.g. USSR -> Russia, Ottoman Empire -> Turkey).\n",
    "# It is important to keep this in mind during our analysis as this will show up as\n",
    "# \"Russia\" having fought in WW2, for example, when really \"USSR\" fought in WW2.\n",
    "# This is okay for our purposes because we are not primarily concerned about\n",
    "# individual states but rather the quantitative things about states that are correlated with war.\n",
    "\n",
    "country_codes = pd.read_csv(\"correlates_of_war/COW-country-codes.csv\")\n",
    "country_codes = country_codes.drop_duplicates()\n",
    "country_codes = country_codes.set_index(\"CCode\")\n",
    "country_dict = country_codes.to_dict(\"index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'StateAbb': 'USA', 'StateNme': 'United States of America'}\n",
      "{'StateAbb': 'CAN', 'StateNme': 'Canada'}\n",
      "{'StateAbb': 'RUS', 'StateNme': 'Russia'}\n",
      "Not a valid country code\n"
     ]
    }
   ],
   "source": [
    "# Here we are checking that this worked correctly by plugging in some of\n",
    "# the country codes and making sure they are associated with the right country.\n",
    "\n",
    "print(country_dict[2]) # should be USA\n",
    "print(country_dict[20]) # should be Canada\n",
    "print(country_dict[365]) # should be Russia\n",
    "try:\n",
    "    print(country_dict[3]) # no country associated with this code, should throw a KeyError\n",
    "except KeyError:\n",
    "    print(\"Not a valid country code\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we are going to read in the rest of our csv files. Some of the files use Latin-1 encoding which\n",
    "# causes problems when we try read it in with pandas as pandas assumes UTF-8 by default. To make this simpler\n",
    "# I wrote a short function that will figure out the encoding. This isn't the most efficient, but it's\n",
    "# not too slow and it works.\n",
    "def get_encoding(filename):\n",
    "    with open(filename, \"rb\") as f:\n",
    "        return chardet.detect(f.read())[\"encoding\"]\n",
    "\n",
    "filename = \"correlates_of_war/COW War Data/Dyadic-Interstate-War-Dataset/directed_dyadic_war.csv\"\n",
    "war = pd.read_csv(filename, encoding=get_encoding(filename))\n",
    "\n",
    "filename = \"correlates_of_war/Diplomatic Exchange/Diplomatic_Exchange_2006v1.csv\"\n",
    "diplomatic_exchanges = pd.read_csv(filename, encoding=get_encoding(filename))\n",
    "\n",
    "filename = \"correlates_of_war/Colonial Contiguity/contcol.csv\"\n",
    "colonial_contiguity = pd.read_csv(filename, encoding=get_encoding(filename))\n",
    "\n",
    "filename = \"correlates_of_war/Direct Contiguity/contdird.csv\"\n",
    "direct_contiguity = pd.read_csv(filename, encoding=get_encoding(filename))\n",
    "\n",
    "filename = \"correlates_of_war/Formal Alliances/alliance_v4.1_by_dyad_yearly.csv\"\n",
    "formal_alliances = pd.read_csv(filename, encoding=get_encoding(filename))\n",
    "\n",
    "filename = \"correlates_of_war/Militarized Interstate Disputes/dyadic_mid_4.02.csv\"\n",
    "mid = pd.read_csv(filename, encoding=get_encoding(filename))\n",
    "\n",
    "filename = \"correlates_of_war/National Material Capabilities/NMC-60-abridged/NMC-60-abridged.csv\"\n",
    "nmc = pd.read_csv(filename, encoding=get_encoding(filename))\n",
    "\n",
    "filename = \"correlates_of_war/State System Membership/majors2016.csv\"\n",
    "major_powers = pd.read_csv(filename, encoding=get_encoding(filename))\n",
    "\n",
    "filename = \"correlates_of_war/Territorial Change/tc2018.csv\"\n",
    "territorial_change = pd.read_csv(filename, encoding=get_encoding(filename))\n",
    "\n",
    "filename = \"correlates_of_war/Trade/Dyadic_COW_4.0.csv\"\n",
    "trade = pd.read_csv(filename, encoding=get_encoding(filename))\n",
    "\n",
    "filename = \"correlates_of_war/World Religion/WRP_national.csv\"\n",
    "religion = pd.read_csv(filename, encoding=get_encoding(filename))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Data Cleaning**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Luckily for us, the Correlates of War Project has spent a lot of time making their data as easy to use as possible, which includes interpolating missing data sometimes or indicating that the data is missing otherwise. For example, -9 typically means missing data. I've looked through the codebooks that are provided with each dataset and can say that everywhere negative integers occur, it is meant to signify data is missing or not applicable, and so we can safely replace all instances of negative integers with NaN. We do this so that these negative numbers don't affect our analysis later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping all the columns we don't need\n",
    "nmc = nmc.drop(columns=['stateabb', 'milex', 'milper', 'irst', 'pec', 'tpop', 'upop', 'version'])\n",
    "\n",
    "colonial_contiguity = colonial_contiguity.drop(columns=['dyad', 'statelab', 'dependl', 'statehab', 'dependh', 'version'])\n",
    "\n",
    "direct_contiguity = direct_contiguity.drop(columns=['dyad', 'state1ab', 'state2ab', 'version'])\n",
    "\n",
    "trade = trade.drop(columns=['importer1', 'importer2', 'smoothflow1', 'smoothflow2', 'smoothtotrade', 'spike1', 'spike2', \n",
    "                    'dip1', 'dip2', 'trdspike', 'tradedip', 'bel_lux_alt_flow1', 'bel_lux_alt_flow2', 'china_alt_flow1', 'china_alt_flow2',\n",
    "                    'source1', 'source2', 'version'])\n",
    "\n",
    "diplomatic_exchanges = diplomatic_exchanges.drop(columns=['version'])\n",
    "\n",
    "territorial_change = territorial_change.drop(columns=['month', 'gaintype', 'procedur', 'entity', 'contgain', 'area', 'pop', 'portion', \n",
    "                                 'losetype', 'contlose', 'entry', 'exit', 'number', 'indep', 'conflict', 'version'])\n",
    "\n",
    "# go through the codebook again, probably want to use strtyr instead of year, might want to use some of these (if I'm using all those diplo ones\n",
    "# should definitely use a few of these)\n",
    "mid = mid.drop(columns=['disno', 'dyindex', 'namea', 'nameb', 'strtday', 'strtmnth', 'strtyr', 'endday', 'endmnth', 'endyear', 'settlmnt', \n",
    "                        'fatlev', 'highact', 'hihost', 'recip', 'noinit', 'notarg', 'sideaa', 'revstata', 'revtypea', 'fatleva', \n",
    "                        'highmcaa', 'hihosta', 'orignata', 'sideab', 'revstatb', 'revtypeb', 'fatlevb', 'highmcab', 'hihostb', \n",
    "                        'orignatb', 'rolea', 'roleb', 'dyad_rolea', 'dyad_roleb', 'durindx', 'duration', 'cumdurat', 'mid5hiact', \n",
    "                        'mid5hiacta', 'mid5hiactb', 'severity', 'severitya', 'severityb', 'ongo2014', 'new', 'change', 'changetype_1',\n",
    "                        'changetype_2', 'dyad', 'abbreva', 'abbrevb', 'lastobs', 'newar', 'outcome', 'war'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "war = war.drop(columns=['warnum', 'disno', 'dyindex', 'warstrtmnth', 'warstrtday', 'warstrtyr', 'warendmnth', 'warenday', 'warendyr', 'warolea', \n",
    "                        'waroleb', 'wardyadrolea', 'wardyadroleb', 'batdtha', 'batdthb', 'batdths', 'outcomea', 'changes_1', 'changes_2', 'durindx'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The datasets typically use -9 to mean missing value, but some use -8. Regardless,\n",
    "# negative integers are codes for something and not actual data so we can safely replace\n",
    "# these with NaN.\n",
    "def replace_missing(df):\n",
    "    return df.applymap((lambda x: np.nan if x == -9 or x == -8 else x))\n",
    "\n",
    "war = replace_missing(war)\n",
    "diplomatic_exchanges = replace_missing(diplomatic_exchanges)\n",
    "colonial_contiguity = replace_missing(colonial_contiguity)\n",
    "direct_contiguity = replace_missing(direct_contiguity)\n",
    "formal_alliances = replace_missing(formal_alliances)\n",
    "mid = replace_missing(mid)\n",
    "nmc = replace_missing(nmc)\n",
    "trade = replace_missing(trade)\n",
    "religion = replace_missing(religion)\n",
    "territorial_change = replace_missing(territorial_change)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# have to do something about missing data, if I want to just leave it, \n",
    "# need to explain why, could maybe do interpolation here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "what do we want to do"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "want to do more checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cinc in nmc is our capability number, look at documentation to see what it means\n",
    "# want to do logistic regression for war or no war between two countries based on:\n",
    "# capability difference -done\n",
    "# geographical proximity -done\n",
    "# trade -done\n",
    "# something with allies?\n",
    "# diplomatic exchanges/what kind -done\n",
    "# recent territorial change -done\n",
    "# num militarized disputes\n",
    "\n",
    "# first want to do logistic regression of just militarized disputes with war, should be correlated pretty highly\n",
    "# want to do linear regression of num militarized disputes with the rest of the variables I listed above\n",
    "\n",
    "# don't care about which state is which, just the numbers relative to each other\n",
    "# I think I want a dataframe that has a row for every dyad for every year\n",
    "# each row should have a number for the variables I listed above, then a boolean for if they are at war or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we are calculating the percent difference in military capabilities between each\n",
    "# country and every other country for each year in the dataset (1816-2016).\n",
    "def percent_diff(row):\n",
    "    rest = nmc[(nmc['ccode'] != row['ccode']) & (nmc['year'] == row['year'])]\n",
    "    cinc_diff = row['cinc'] - rest['cinc'].values\n",
    "    cinc_sum = row['cinc'] + rest['cinc'].values\n",
    "    percent_diff = (cinc_diff / cinc_sum / 2) * 100\n",
    "    ccode1 = np.full_like(rest['ccode'].values, row['ccode'])\n",
    "    year = np.full_like(ccode1, row['year'])\n",
    "    return pd.DataFrame(\n",
    "        {'year': year, 'ccode1': ccode1, 'ccode2': rest['ccode'].values, 'capability_percent_diff': percent_diff})\n",
    "\n",
    "percent_diff_df = nmc.apply(percent_diff, axis=1)\n",
    "df = pd.concat(percent_diff_df.tolist(), axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wesley/anaconda3/lib/python3.9/site-packages/pandas/core/reshape/merge.py:916: FutureWarning: In a future version, the Index constructor will not infer numeric dtypes when passed object-dtype sequences (matching Series behavior)\n",
      "  key_col = Index(lvals).where(~mask_left, rvals)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1912350\n",
      "1912350\n"
     ]
    }
   ],
   "source": [
    "# Adding direct contiguity, both datasets cover 1816-2016. conttype:\n",
    "# 1 = separated by a land or river border\n",
    "# 2 = separated by <= 12 miles of water\n",
    "# 3 = separated by (12, 24] miles of water or less\n",
    "# 4 = separated by (24, 150] miles of water or less\n",
    "# 5 = separated by (150, 400] miles of water or less\n",
    "# 6 = separated by > 400 miles of water or no direct route (e.g. Afghanistan and Kazakhstan)\n",
    "\n",
    "# In this dataset, they do not have an entry for every year. Instead, they have a begin year and an end year.\n",
    "# Here we are exploding the DataFrame to have an entry for each year between the begin and end year.\n",
    "# This creates some duplicate rows, which we drop.\n",
    "colonial_contiguity['year'] = \\\n",
    "    [range(begin, end + 1) for begin, end in zip(colonial_contiguity['begin'], colonial_contiguity['end'])]\n",
    "colonial_contiguity = colonial_contiguity.explode('year')\n",
    "colonial_contiguity = colonial_contiguity.drop(columns=['begin', 'end'])\n",
    "colonial_contiguity = colonial_contiguity.drop_duplicates()\n",
    "colonial_contiguity = colonial_contiguity.rename(columns={'statelno': 'ccode1', 'statehno': 'ccode2'})\n",
    "\n",
    "# colonial_contiguity only has one row per dyad, rather than two rows like the\n",
    "# DataFrame we're building. To fix this, we just make a copy of colonial_contiguity and \n",
    "# switch the names of the columns, then concatenate them together.\n",
    "colonial_contiguity = pd.concat(\n",
    "    [colonial_contiguity, colonial_contiguity.rename(columns={'ccode1': 'ccode2', 'ccode2': 'ccode1'})], ignore_index=True)\n",
    "\n",
    "direct_contiguity = direct_contiguity.rename(columns={'state1no': 'ccode1', 'state2no': 'ccode2'})\n",
    "\n",
    "# Now we are merging our two contiguity DataFrames based on ccode1, ccode2, and year. This results\n",
    "# in two conttype columns, conttype_1 and conttype_2 (that's what the suffixes= is for), conttype_1\n",
    "# is the value from conttype in direct_contiguity and conttype_2 is the one from colonial_contiguity.\n",
    "direct_contiguity = pd.merge(\n",
    "    direct_contiguity, colonial_contiguity, on=['ccode1', 'ccode2', 'year'], how='outer', suffixes=('_1', '_2'))\n",
    "\n",
    "# The merge will fill in NaN in conttype_1 and conttype_2 when there was not a corresponding entry\n",
    "# in the other DataFrame. For example, in 1816 USA and UK did not have direct contiguity, but they did\n",
    "# have a colonial contiguity through Canada. So, in this example conttype_1 would be NaN and conttype_2 would be 1.\n",
    "# We are replacing these NaNs with 6, indicating no contiguity, then finding our true conttype value by taking the\n",
    "# minimum of the two conttypes.\n",
    "direct_contiguity = direct_contiguity.fillna(6)\n",
    "direct_contiguity['conttype'] = direct_contiguity[['conttype_1', 'conttype_2']].min(axis=1)\n",
    "direct_contiguity = direct_contiguity.drop(columns=['conttype_1', 'conttype_2'])\n",
    "\n",
    "# There are multiple rows where year, ccode1, and ccode2 match but with different conttypes.\n",
    "# So we have to find the minimum of these, and then drop the rest. To do this, we group by\n",
    "# year, ccode1, and ccode2, then sort them so that the smallest value is the first row.\n",
    "# We can then drop rows where year, ccode1, and ccode2 are equal only keeping the first as\n",
    "# we know this the smallest one. This is a long operation, it takes ~40 seconds on my computer.\n",
    "direct_contiguity = direct_contiguity.groupby(['year', 'ccode1', 'ccode2']).apply(lambda x: x.sort_values('conttype'))\n",
    "direct_contiguity = direct_contiguity.reset_index(drop=True)\n",
    "direct_contiguity = direct_contiguity.drop_duplicates(subset=['year', 'ccode1', 'ccode2'], keep='first')\n",
    "\n",
    "# Adding conttype to our DataFrame.\n",
    "# We can do outer or left merge here, as df already contains every directed dyad for every year.\n",
    "# I use outer just to be safe, and then we can check that no new rows were added (indicating that\n",
    "# we really do already have every directed dyad).\n",
    "print(len(df))\n",
    "df = pd.merge(df, direct_contiguity, on=['ccode1', 'ccode2', 'year'], how='outer')\n",
    "df['conttype'] = df['conttype'].fillna(6)\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1912350\n",
      "1912350\n"
     ]
    }
   ],
   "source": [
    "# Trade dataset is from 1870-2014\n",
    "# flow1 = imports of ccode1 from ccode2 in millions of 2014 USD\n",
    "# flow2 = exports of ccode1 to ccode2 in millions of 2014 USD\n",
    "\n",
    "# Like with colonial_contiguity, this dataset only has one row for each dyad rather than two like we want.\n",
    "# Fixing it in the exact same way as before, except this time we also need to switch flow1 and flow2.\n",
    "trade = pd.concat([trade, trade.rename(columns={'ccode1': 'ccode2', 'ccode2': 'ccode1', 'flow1': 'flow2', 'flow2': 'flow1'})])\n",
    "\n",
    "# Calculating imports/export each country has with another by its relative amount\n",
    "# to that country's total trade in a given year as a percentage. E.g. if the US exports\n",
    "# a total of $1 billion of goods in a year and exports $500 million to Canada\n",
    "# then USA's export_percent with Canada is 50.\n",
    "grouped = trade.groupby(['ccode1', 'year'])[['flow1', 'flow2']].transform('sum')\n",
    "trade['flow1_sum'] = grouped['flow1']\n",
    "trade['flow2_sum'] = grouped['flow2']\n",
    "trade['import_percent'] = (trade['flow1'] / trade['flow1_sum']) * 100\n",
    "trade['export_percent'] = (trade['flow2'] / trade['flow2_sum']) * 100\n",
    "trade = trade.drop(columns=['flow1', 'flow1_sum', 'flow2', 'flow2_sum'])\n",
    "\n",
    "# Adding these two columns to our DataFrame.\n",
    "# Again, we'll use an outer merge to be safe, and we can check that no new rows were added.\n",
    "print(len(df))\n",
    "df = pd.merge(df, trade, on=['ccode1', 'ccode2', 'year'], how='outer')\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1912350\n",
      "1912350\n"
     ]
    }
   ],
   "source": [
    "# Diplomatic Exchanges. Data is from 1817-2005, but in increments ranging from 3-10 years (typically 5)\n",
    "# The data is already fine as is, so we can just merge it.\n",
    "print(len(df))\n",
    "df = pd.merge(df, diplomatic_exchanges, on=['ccode1', 'ccode2', 'year'], how='outer')\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1912350\n",
      "1912414\n"
     ]
    }
   ],
   "source": [
    "# Territorial Change (1816-2008)\n",
    "# We are going to keep things simple and make this binary. If a country gained land from another country then\n",
    "# we'll put a 1 in the gained_territory column, 0 otherwise. If a county lost land from another country then\n",
    "# we'll put a 1 in the lost_territory column, 0 otherwise.\n",
    "\n",
    "# Dropping rows that contain NaN, as if we don't know the year or who gained or lost territory, the data is worthless to us.\n",
    "territorial_change = territorial_change.dropna()\n",
    "\n",
    "# Here we are creating a new column in territorial_change and setting all those values to true\n",
    "# and then copying territorial_change and renaming some of the columns. We then merge these with\n",
    "# our main DataFrame which results in True everywhere there was a match between year, ccode1, and ccode2,\n",
    "# and NaN everywhere else. We then fill in NaN with False in the two new columns we added.\n",
    "territorial_change = territorial_change.rename(columns={'gainer': 'ccode1', 'loser': 'ccode2'})\n",
    "territorial_change['gained_territory'] = 1\n",
    "losers = territorial_change.rename(columns={'ccode1': 'ccode2', 'ccode2': 'ccode1', 'gained_territory': 'lost_territory'})\n",
    "print(len(df))\n",
    "df = pd.merge(df, territorial_change, on=['ccode1', 'ccode2', 'year'], how='left')\n",
    "df = pd.merge(df, losers, on=['ccode1', 'ccode2', 'year'], how='left')\n",
    "print(len(df))\n",
    "df[['gained_territory', 'lost_territory']] = df[['gained_territory', 'lost_territory']].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1912350\n",
      "1912360\n"
     ]
    }
   ],
   "source": [
    "# war (1816-2010)\n",
    "# dataset already has directed dyads for every year (e.g. war between a and b that lasted from 1999-2000 has 4 entries)\n",
    "\n",
    "war = war.rename(columns={'statea': 'ccode1', 'stateb': 'ccode2'})\n",
    "war['at_war'] = 1\n",
    "print(len(df))\n",
    "df = pd.merge(df, war, on=['ccode1', 'ccode2', 'year'], how='outer')\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1912350\n"
     ]
    }
   ],
   "source": [
    "df = df.drop_duplicates()\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['at_war'] = df['at_war'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.003622\n",
      "         Iterations 12\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                 at_war   No. Observations:              1240765\n",
      "Model:                          Logit   Df Residuals:                  1240749\n",
      "Method:                           MLE   Df Model:                           15\n",
      "Date:                Tue, 09 May 2023   Pseudo R-squ.:                  0.1033\n",
      "Time:                        18:05:08   Log-Likelihood:                -4494.3\n",
      "converged:                       True   LL-Null:                       -5012.1\n",
      "Covariance Type:            nonrobust   LLR p-value:                3.318e-211\n",
      "==================================================================================================================================\n",
      "                                                                     coef    std err          z      P>|z|      [0.025      0.975]\n",
      "----------------------------------------------------------------------------------------------------------------------------------\n",
      "Intercept                                                         -4.5789      0.102    -44.699      0.000      -4.780      -4.378\n",
      "capability_percent_diff                                           -0.0116      0.003     -3.585      0.000      -0.018      -0.005\n",
      "conttype                                                          -0.6216      0.021    -29.943      0.000      -0.662      -0.581\n",
      "capability_percent_diff:conttype                                   0.0026      0.001      4.200      0.000       0.001       0.004\n",
      "import_percent                                                    -0.0196      0.012     -1.662      0.097      -0.043       0.004\n",
      "capability_percent_diff:import_percent                             0.0012      0.000      3.878      0.000       0.001       0.002\n",
      "conttype:import_percent                                            0.0132      0.002      5.817      0.000       0.009       0.018\n",
      "capability_percent_diff:conttype:import_percent                   -0.0002   5.94e-05     -3.194      0.001      -0.000   -7.33e-05\n",
      "export_percent                                                    -0.0002      0.011     -0.021      0.983      -0.022       0.021\n",
      "capability_percent_diff:export_percent                             0.0009      0.000      2.581      0.010       0.000       0.002\n",
      "conttype:export_percent                                            0.0093      0.002      4.062      0.000       0.005       0.014\n",
      "capability_percent_diff:conttype:export_percent                -1.301e-05   6.99e-05     -0.186      0.852      -0.000       0.000\n",
      "import_percent:export_percent                                      0.0003      0.000      1.873      0.061   -1.38e-05       0.001\n",
      "capability_percent_diff:import_percent:export_percent          -1.979e-05   4.56e-06     -4.341      0.000   -2.87e-05   -1.09e-05\n",
      "conttype:import_percent:export_percent                            -0.0001   3.44e-05     -3.936      0.000      -0.000   -6.81e-05\n",
      "capability_percent_diff:conttype:import_percent:export_percent  2.657e-06   9.59e-07      2.771      0.006    7.77e-07    4.54e-06\n",
      "==================================================================================================================================\n"
     ]
    }
   ],
   "source": [
    "model = sm.formula.logit('at_war ~ capability_percent_diff * conttype * import_percent * export_percent', data=df).fit()\n",
    "print(model.summary())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
